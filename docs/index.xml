<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Koda86 Blog</title>
<link>https://koda86.github.io/</link>
<atom:link href="https://koda86.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>Posts on statistics, biomechanics, and other topics.</description>
<generator>quarto-1.6.42</generator>
<lastBuildDate>Fri, 02 Jan 2026 23:00:00 GMT</lastBuildDate>
<item>
  <title>Why Overlapping Confidence Intervals Are Potentially Misleading</title>
  <dc:creator>Daniel Koska</dc:creator>
  <link>https://koda86.github.io/posts/2026-03-01-overlapping_confidence_intervals.html</link>
  <description><![CDATA[ 




<p>Again, this post is more of a reference for future debates than a mathematically or statistically sound evaluation of the topic. There will probably be more posts like this in the future, maybe even a separate “Answers-to-FAQ” section. Also, I would be surprised if there aren’t any similar (and probably better) posts and answers available online. Cross Validated seems like a strong candidate here. However, I did not check the internet extensively prior to writing this since I really wanted this to be my personal explanation plus I wanted to increase the chance of being able to remember/recall this later on.</p>
<section id="some-background" class="level3">
<h3 class="anchored" data-anchor-id="some-background">Some background</h3>
<p>One of the things that haunt me since I visited my first statistics course at the university (btw., back then we were taught to analyze data in Excel sheets o_O) was that researchers regularly use overlap in confidence intervals (CIs) to analyze statistical significance of mean group differences between two groups. The idea is to use some visualization device such as a box plot (I believe back then we used bar plots) to plot the dispersion of data in both groups right next to each other. You then add CIs to these plots and check if they overlap (see Fig. 1).</p>
<p>Fig. 1</p>
<p>Not sure I was a aware about this back then, but CIs and statistical tests (e.g., t-tests) really seem to alike mathematically at a first glance.</p>
<p>… Explain this with formulas …</p>
<p>I believe that question I carried with me for years is this: Are overlapping confidence intervals a valid replacement for statistical tests of mean differences or rather a rough heuristic that is potentially problematic/misleading? My intuition tells me the latter is true, so the idea of this post is to investigate this using a small example with simulated data.</p>
</section>
<section id="why-overlap-is-not-significance" class="level3">
<h3 class="anchored" data-anchor-id="why-overlap-is-not-significance">Why overlap is not significance</h3>
<p>From my understanding, there are three primary reasons why overlap is not a good subsitute for tests of statistical significance:</p>
<ol type="1">
<li><strong>Confidence intervals are for indivual estimates, not for their difference:</strong> …</li>
<li><strong>The difference has it’s own sampling variability:</strong> This is a particularly important and reoccuring point, …</li>
<li><strong>The overlap heuristic only works under specific conditions/assumptions:</strong> …</li>
</ol>
<p>Then it updates the mean shape and repeats until everything stops changing much.</p>
</section>
<section id="cumming-and-finch-2005" class="level3">
<h3 class="anchored" data-anchor-id="cumming-and-finch-2005">Cumming and Finch (2005)</h3>
<p>Lorem ipsum.</p>
</section>
<section id="best-practice" class="level3">
<h3 class="anchored" data-anchor-id="best-practice">Best practice</h3>
<p>Lorem ipsum.</p>
</section>
<section id="simlation-example" class="level3">
<h3 class="anchored" data-anchor-id="simlation-example">Simlation example</h3>
<p>Lorem ipsum.</p>


<!-- -->

</section>

 ]]></description>
  <category>confidence intervals</category>
  <category>statistical significance</category>
  <guid>https://koda86.github.io/posts/2026-03-01-overlapping_confidence_intervals.html</guid>
  <pubDate>Fri, 02 Jan 2026 23:00:00 GMT</pubDate>
</item>
<item>
  <title>How Isotropic Scaling Works in Generalized Procrustes Analysis</title>
  <dc:creator>Daniel Koska</dc:creator>
  <link>https://koda86.github.io/posts/2025-08-12-isotropic-scaling-gpa.html</link>
  <description><![CDATA[ 




<p>This entry is more of a mental note for my future self than anything else (which I guess most of this blog is tbh).</p>
<p>If you’ve ever worked with Generalized Procrustes Analysis (GPA) in statistical shape modeling, you’ve probably come across the <em>isotropic scaling</em> step. It sounds innocent enough — just scale all coordinates equally — but this step is both powerful and a little sneaky. Let’s unpack what’s really going on.</p>
<section id="where-it-fits-in-gpa" class="level3">
<h3 class="anchored" data-anchor-id="where-it-fits-in-gpa">Where it fits in GPA</h3>
<p>The core idea of GPA is to remove differences that are <em>not</em> actual shape variation — things like translation, rotation, and scale — so that PCA or other analyses reflect pure shape.</p>
<p>For each shape (X) compared to a reference (often the current mean shape), GPA does:</p>
<ol type="1">
<li><strong>Translation:</strong> Move the centroid to the origin.</li>
<li><strong>Isotropic scaling:</strong> Resize uniformly in all directions to match the reference size.</li>
<li><strong>Rotation:</strong> Rotate to minimize the distance to the reference.</li>
</ol>
<p>Then it updates the mean shape and repeats until everything stops changing much.</p>
</section>
<section id="what-isotropic-scaling-really-is" class="level3">
<h3 class="anchored" data-anchor-id="what-isotropic-scaling-really-is">What isotropic scaling really is</h3>
<p>Isotropic scaling means multiplying <strong>all</strong> coordinates by the same scalar (s).<br>
No stretching in one direction, no skewing — every axis gets scaled equally.</p>
<p>Mathematically, if (X ^{k m}) is a translated shape (with (k) points in (m) dimensions, usually (m=2) or (3)), the scaled shape is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX_%7B%5Ctext%7Bscaled%7D%7D%20=%20s%20%5C,%20X%0A"></p>
<p>The scalar (s &gt; 0) is chosen so that the scaled shape is as close as possible to the reference (Y).</p>
</section>
<section id="deriving-the-scaling-factor" class="level3">
<h3 class="anchored" data-anchor-id="deriving-the-scaling-factor">Deriving the scaling factor</h3>
<p>We want to minimize the squared Procrustes distance:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AD%5E2(s)%20=%20%5C%7C%5C,%20sX%20-%20Y%20%5C,%5C%7C_F%5E2%0A"></p>
<p>where (||_F) is the Frobenius norm (sum of squared coordinates, square-rooted).</p>
<p>Expanding and differentiating with respect to (s):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AD%5E2(s)%20=%20s%5E2%20%5Csum_%7Bi,j%7D%20X_%7Bij%7D%5E2%20-%202s%20%5Csum_%7Bi,j%7D%20X_%7Bij%7D%20Y_%7Bij%7D%20+%20%5Csum_%7Bi,j%7D%20Y_%7Bij%7D%5E2%0A"></p>
<p>Set derivative to zero:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A2s%20%5Csum_%7Bi,j%7D%20X_%7Bij%7D%5E2%20-%202%20%5Csum_%7Bi,j%7D%20X_%7Bij%7D%20Y_%7Bij%7D%20=%200%0A"></p>
<p>And solve:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0As%20=%20%5Cfrac%7B%5Csum_%7Bi,j%7D%20X_%7Bij%7D%20Y_%7Bij%7D%7D%7B%5Csum_%7Bi,j%7D%20X_%7Bij%7D%5E2%7D%0A"></p>
<p>In matrix form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0As%20=%20%5Cfrac%7B%5Cmathrm%7Btrace%7D(X%5E%5Cmathsf%7BT%7D%20Y)%7D%7B%5Cmathrm%7Btrace%7D(X%5E%5Cmathsf%7BT%7D%20X)%7D%0A"></p>
</section>
<section id="the-centroid-size-connection" class="level3">
<h3 class="anchored" data-anchor-id="the-centroid-size-connection">The centroid size connection</h3>
<p>If no specific reference is chosen yet (e.g., the very first iteration), shapes are often scaled to <strong>unit centroid size</strong>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AC%20=%20%5Csqrt%7B%5Csum_%7Bi=1%7D%5Ek%20%5Csum_%7Bj=1%7D%5Em%20X_%7Bij%7D%5E2%7D%0A"></p>
<p>and</p>
<p><img src="https://latex.codecogs.com/png.latex?%0As%20=%20%5Cfrac%7B1%7D%7BC%7D%0A"></p>
<p>This prevents large shapes from dominating the mean early on.</p>
</section>
<section id="why-it-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-it-matters">Why it matters</h3>
<p>Without scaling, size differences will dominate PCA.<br>
With isotropic scaling, we remove those size differences, leaving only relative point configurations.<br>
That’s great for <em>pure shape</em> analysis — but it can be risky if size is biologically meaningful.</p>
<p>And here’s the catch: isotropic scaling ties <em>all</em> coordinate axes to a single size factor.<br>
If your sample varies in length or width, this scaling will also change <strong>vertical coordinates</strong>, even if they were identical before.<br>
That can create <em>artificial deformation</em> in anisotropic structures like weight-bearing feet — a subtle source of bias you might not expect.</p>


<!-- -->

</section>

 ]]></description>
  <category>statistical-shape-modeling</category>
  <category>gpa</category>
  <category>scaling</category>
  <guid>https://koda86.github.io/posts/2025-08-12-isotropic-scaling-gpa.html</guid>
  <pubDate>Mon, 11 Aug 2025 22:00:00 GMT</pubDate>
</item>
</channel>
</rss>
