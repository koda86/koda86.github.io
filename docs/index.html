<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Daniel Koska – Koda86 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-listing/list.min.js"></script>
<script src="site_libs/quarto-listing/quarto-listing.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-de84f8d6bb715db06a919283c2d1e787.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5410ef2b9baaa0d85679240150568bab.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-latest .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-date','listing-title','listing-author','listing-image','listing-description','listing-categories',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      
      searchColumns: ["listing-date","listing-title","listing-author","listing-image","listing-description","listing-categories"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-latest'] = new List('listing-latest', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<link rel="alternate" type="application/rss+xml" title="Koda86 Blog" href="index.xml" data-external="1"></head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Koda86 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/koda86/koda86.github.io"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#latest-posts" id="toc-latest-posts" class="nav-link active" data-scroll-target="#latest-posts">Latest Posts</a></li>
  <li><a href="#software-contributions" id="toc-software-contributions" class="nav-link" data-scroll-target="#software-contributions">Software Contributions</a></li>
  <li><a href="#how-isotropic-scaling-in-gpa-works" id="toc-how-isotropic-scaling-in-gpa-works" class="nav-link" data-scroll-target="#how-isotropic-scaling-in-gpa-works">How Isotropic Scaling in GPA Works</a></li>
  <li><a href="#disco-diffusion-music-video" id="toc-disco-diffusion-music-video" class="nav-link" data-scroll-target="#disco-diffusion-music-video">Disco Diffusion Music Video</a></li>
  <li><a href="#isolating-bass-tracks" id="toc-isolating-bass-tracks" class="nav-link" data-scroll-target="#isolating-bass-tracks">Isolating Bass Tracks</a></li>
  </ul>
</nav>
    <h5 class="quarto-listing-category-title">Categories</h5><div class="quarto-listing-category category-default"><div class="category" data-category="">All <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Z3Bh">gpa <span class="quarto-category-count">(1)</span></div><div class="category" data-category="c2NhbGluZw==">scaling <span class="quarto-category-count">(1)</span></div><div class="category" data-category="c3RhdGlzdGljYWwtc2hhcGUtbW9kZWxpbmc=">statistical-shape-modeling <span class="quarto-category-count">(1)</span></div></div></div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Daniel Koska</h1>
<p class="subtitle lead">Data; Science; Biomechanics</p>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<p>Welcome to my blog.</p>
<p>This is intended to be a collection of ongoing and past projects, papers, coding adventures and whatever else seems worth sharing. This blog’s running on GitHub Pages and is written using Quarto, (hopefully) making it easy to share code examples. And hey, if you spot something cool, you can dive straight into the GitHub repo and start playing around with it.</p>
<section id="latest-posts" class="level2">
<h2 class="anchored" data-anchor-id="latest-posts">Latest Posts</h2>
<div id="listing-latest" class="quarto-listing quarto-listing-container-default">
<div class="list quarto-listing-default">
<div class="quarto-post image-right" data-index="0" data-categories="c3RhdGlzdGljYWwtc2hhcGUtbW9kZWxpbmclMkNncGElMkNzY2FsaW5n" data-listing-date-sort="1754949600000" data-listing-file-modified-sort="1756046150584" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="3" data-listing-word-count-sort="434">
<div class="thumbnail">
<p><a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external"></a></p><a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external">
<div class="listing-item-img-placeholder card-img-top" >&nbsp;</div>
</a><p><a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external"></a></p>
</div>
<div class="body">
<h3 class="no-anchor listing-title">
<a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external">How Isotropic Scaling Works in Generalized Procrustes Analysis</a>
</h3>
<div class="listing-subtitle">
<a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external"></a>
</div>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('c3RhdGlzdGljYWwtc2hhcGUtbW9kZWxpbmc='); return false;">
statistical-shape-modeling
</div>
<div class="listing-category" onclick="window.quartoListingCategory('Z3Bh'); return false;">
gpa
</div>
<div class="listing-category" onclick="window.quartoListingCategory('c2NhbGluZw=='); return false;">
scaling
</div>
</div>
<div class="listing-description">
<a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external">A deep dive into isotropic scaling in GPA with formulas, intuition, and potential pitfalls.</a>
</div>
</div>
<div class="metadata">
<a href="./posts/2025-08-12-isotropic-scaling-gpa.html" class="no-external">
<div class="listing-date">
Aug 12, 2025
</div>
<div class="listing-author">
Daniel Koska
</div>
</a>
</div>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="software-contributions" class="level2">
<h2 class="anchored" data-anchor-id="software-contributions">Software Contributions</h2>
<details>
<summary>
Click to expand
</summary>
<section id="functional-bootstrapped-bands-funbootband" class="level3">
<h3 class="anchored" data-anchor-id="functional-bootstrapped-bands-funbootband">Functional Bootstrapped Bands (FunBootBand)</h3>
<section id="background-story" class="level4">
<h4 class="anchored" data-anchor-id="background-story">Background story</h4>
<details>
<summary>
Click to expand
</summary>
<p>The whole journey began when I started thinking about ways to adequately characterize differences between joint angles calculated from different measurement systems. In my case, I wanted to compare joint angles from a 3D camera system and an inertial measurement unit system. In terms of choosing appropriate statistics, there are some good reads about what <strong>not</strong> to do and how to implement methods for <strong>discrete</strong> data. See, e. g., the highly cited work by Bland and Altman (e.g the papers form 1986, or 2007), who introduced the so called Limits of Agreement (LoA) approach. There’s much less literature, however, on how to handle continuous differences between two measurement systems.</p>
<p>One paper that caught my attention is the article by <a href="https://doi.org/10.1016/j.gaitpost.2012.05.001">Røslien et al., (2012)</a>, which describes a way to expand the LoA method to continuous data by using a functional approach. The paper in a nutshell: Continuous data (aka curves) are approximated using functions to calculate a functional counterpart of the LoA. The problem, however, is that the approach described in the paper is not entirely functional. Rather, the actual calculation of the Functional Limits of Agreement is carried out for each individual point of the previously determined functional curves (for details see the implementation in the utilized R package <em>fda</em> by James Ramsay). Strictly speaking, this turns the whole idea of using functions on its head and results in functional LoA (or more generally: statistical bands) that are likely too narrow (<a href="https://doi.org/10.1016/j.jbiomech.2023.111506">Koska et al., 2023</a>). Applied to my original problem of describing continuous differences between measurement systems, this would mean that the random measurement error is likely underestimated.</p>
<p>Another paper that describes a functional approach is the one by <a href="https://doi.org/10.1016/S0966-6362(98)00043-5">Lenhoff et al.&nbsp;(1999)</a>, i.e., curves/time series are approximated using functions just like in Røislien et al.&nbsp;(2012). The paper is not specifically about quantifying differences between measurement systems, but more generally about the construction of statistical bands (more precisely confidence and prediction bands) for biomechanical curve data. The actual hack here is that the distribution of curves is estimated by bootstrapping the coefficients of the curve functions. This means that bands are no longer calculated pointwise, but the entire curve is included in the calculation. The method in Lenhoff et al., to the best of my knowledge, is based on the work of Olshen, Biden, Wyatt, and Sutherland from the 1980s (see, for example, Sutherland et al., 1988; Olshen et al., 1989).</p>
<ul>
<li><p>Sutherland, D., Olshen, R., Biden, E., Wyatt, M., 1988. Development of Mature Walking. Mac Keith Press. Olshen, R.A., Biden, E.N., Wyatt, M.P., Sutherland, D.H., 1989. Gait analysis and the bootstrap. Ann. Statist. 17 (4), <a href="http://dx.doi.org/10.1214/aos/1176347372" class="uri">http://dx.doi.org/10.1214/aos/1176347372</a>.</p></li>
<li><p>Olshen, R.A., Biden, E.N., Wyatt, M.P., Sutherland, D.H., 1989. Gait analysis and the bootstrap. Ann. Statist. 17 (4), <a href="http://dx.doi.org/10.1214/aos/1176347372" class="uri">http://dx.doi.org/10.1214/aos/1176347372</a>.</p></li>
</ul>
<p>As you can see, the method is not exactly new. I was all the more surprised that I wasn’t able to find a coded version of the algorithm online. This forced me to implement the algorithm from scratch, which I did using R and the formulas in the appendix of Lenhoff et al.&nbsp;(1999). Extremely helpful at this point was the Matlab code that a former colleague at our institute, Dr.&nbsp;Doris Oriwol, kindly provided me with. Her code allowed me to cross-check my implementation and correct a couple of mistakes. For instance - if I remember correctly - I struggled to implement the correction facor that adjusts the width of the bands to the desired confidence level. Not sure if I’d gotten it right without Doris’ help. So, full credit to Doris!</p>
<blockquote class="blockquote">
<p><em>As a side note: I am very grateful for people who have the know-how and the time to review the code. The description in the Lenhoff paper is rather brief, and we were not always 100% sure whether we had correctly implemented the algorithm. Further opinions and possible corrections are very welcome.</em></p>
</blockquote>
<p>I’m sure other researchers have been here before and would have loved to read a coded version of the algorithm. My hope is that sharing our code is a major pain release in that regard and will lead to more people adopting the method. As indicated by Lenhoff et al., functional statistical bands are not limited to the description of differences between measurement systems, but are useful wherever the variation of curve data needs to be analyzed statistically. This includes a ton of important tasks such as estimating population parameters, indicating precision, assessing statistical significance, comparing groups, forecasting future observations, quantifying uncertainty in predictions etc..</p>
<hr>
<p>In the course of implementing the method, I noticed something else: The examined bootstrap methods (including that of Røislien) have implemented a naive bootstrap, meaning they assume independence of the curves in the dataset. Accordingly, the papers suggested to include only one curve per subject in the bootstrap. From a methodological point of view, this is somewhat problematic since it ignores the intraindividual variance component. In the context of investigating measurement errors, for instance, this means that the variance across repeated measurements within a person is not taken into account. This may further aggravate the problem of bands being too narrow.</p>
<p>We therefore extended the functional bootstrap bands to include a possibility to account for repeated measurements (i.e., dependent curves). This was realized using the two-stage or double bootstrap described in <a href="https://doi.org/10.1017/CBO9780511802843">Davison and Hinkley (1997)</a>, in which subjects (including all of their curves) are sampled with replacement in the first stage, and one curve per subject is drawn without replacement in the second stage. In addition to sharing our code, this implementation of the two-stage bootstrap is - IMHO - the main contribution of ‘our’ FunBootBand method. A systematic comparison of the method with other methodological approaches for characterizing continuous differences between two measurement systemes (pointwise LoA, Functional LoA, Functional Bootstrapped bands) can be found in in <a href="https://doi.org/10.1016/j.jbiomech.2023.111506">Koska et al.&nbsp;(2023)</a>. Here, we analyzed the coverage probabilites of these models in different error scenarios (simulated and real-world data) and found that the FunBootBands showed superior performance.</p>
<hr>
<p>What follows are various versions of the functional bootstrap bands (ongoing development) in different programming languages. The R code has already been published as a (devtools) package, and I plan to add it to CRAN at some point as well. In addition, I’m currently porting the code to Python. If time permits and I can delve into Julia, this may be next in line. Besides porting the function to different languages to improve the accessibility, my main goal is to increase code efficiency and reduce computation times - after all, bootstrapping is quite a computationally intensive. In R this may be done using RCpp, a C++ version. In Python, there is Cython, which should significantly reduce execution time.</p>
</details></section>
<section id="funbootband-r" class="level4">
<h4 class="anchored" data-anchor-id="funbootband-r">FunBootBand R</h4>
<details>
<summary>
Click to expand
</summary>
<p>The <a href="https://koda86.github.io/FunBootBand/">FunBootBand</a> package contains a function to generate statistical (prediction or confidence) bands from curve data using a functional approach and bootstrapping.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The development version of FunBootBand can be installed from GitHub with:</p>
<p>devtools::install_github(“koda86/FunBootBand”)</p>
</details></section>
<section id="funbootband-python" class="level4">
<h4 class="anchored" data-anchor-id="funbootband-python">FunBootBand Python</h4>
<details>
<summary>
Click to expand
</summary>
<p>The first alpha-ish version is available, see here: <a href="https://github.com/koda86/FunBootBand-python" class="uri">https://github.com/koda86/FunBootBand-python</a></p>
<p>My TODO list still includes a bunch of items, such as extensive testing … I’m getting there. Learned a whole lot about Python in the process as well so far.</p>
</details></section>
<section id="funbootband-rcpp" class="level4">
<h4 class="anchored" data-anchor-id="funbootband-rcpp">FunBootBand RCpp</h4>
<details>
<summary>
Click to expand
</summary>
<p>On my TODO list.</p>
</details></section>
</section>
<section id="effort-to-compress" class="level3">
<h3 class="anchored" data-anchor-id="effort-to-compress">Effort to compress</h3>
<details>
<summary>
Click to expand
</summary>
<p>While trying out different complexity measures, I stumbled upon the ‘effort to compress’ (ETC) method introduced in (Nagaraj et al., 2013). ETC is a complexity measure for which code was originally presented as Matlab and Python Code. This repository contains an R implementation of the algorithm.</p>
<p><a href="https://github.com/koda86/effort2compress">effort2compress</a> (GitHub)</p>
<p>See also the website of Nithin Nagaraj for the Matlab and Python versions: <a href="https://sites.google.com/site/nithinnagaraj2/journal/software-toolbox-for-etc-measure">Website Nagaraj</a></p>
<p>Python implementation: <a href="https://github.com/pranaysy/ETCPy">Github</a></p>
</details></section>
<section id="identify-duplicates-in-metadata-duplicheck" class="level3">
<h3 class="anchored" data-anchor-id="identify-duplicates-in-metadata-duplicheck">Identify duplicates in metadata (DupliCheck)</h3>
<details>
<summary>
Click to expand
</summary>
<!-- TODO: Implementieren eines schnelleren Suchalgorithmus -->
<div id="image-container" style="text-align: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DupliCheck_logo.png" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption>DupliCheck</figcaption>
</figure>
</div>
</div>
<p>I was recently conducting a meta-analysis to get an idea of the effect of digital physiotherapy for the treatment of various orthopedic diseases. For this, I used Pubmed, Cochrane, BASE (Bielefeld Academic Search Engine) and Embase, which resulted in large csv files containing metadata from the identified scientific articles. This metadata includes paper titles, authors, and the DOI, among others. Not going to talk about the pain of designing adequate search strings and exporting these articles here …</p>
<p>Before deciding which papers to include in the meta-analysis, I needed to identify duplicates, i.e., papers that appeared more than once. This seems like a fairly straightforward job, but, as usual, the devil is in the detail. This probably explains why I wasn’t able to find a suitable R function for the job (though, to be honest, I didn’t invest an awful lot of time searching).</p>
<p>One obvious candidate, the base function duplicated(), only works on exact copies of a string and fails if even a single character is off. This happens, for example, when author names are written differently across databases. For instance, the author “Çelik” is not the same as “Celik.” Another issue is that two distinct papers can have identical titles and the same authors (in a different order). This should be discernible from their different DOIs, but DOIs are not always available and often come in various formats. The list of complications goes on, making the task more complex. To spare others from the same pain, I packed everything into a small R package called <strong>DupliCheck</strong>.</p>
<p>The package contains a single function called <strong>dupliHunter</strong>. dupliHunter takes a data frame with (at least) title, author, and DOI columns. It also includes a threshold parameter to possibly fine-tune the allowed similarity between titles (calculated using stringdist::stringdistmatrix with the Jaccard distance method).</p>
<p>Here’s how you can use the package:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(usethis)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(devtools)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># devtools::install_github("koda86/DupliCheck")</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DupliCheck)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"~/tmp/data.RData"</span>) <span class="co"># Example data; load your own data here</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>duplicates <span class="ot">&lt;-</span> <span class="fu">dupliHunter</span>(data,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                            <span class="at">title_col =</span> <span class="st">"Title"</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                            <span class="at">author_col =</span> <span class="st">"Authors"</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                            <span class="at">doi_col =</span> <span class="st">"DOI"</span>,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                            <span class="at">threshold =</span> <span class="fl">0.03</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The current version of the function works decently. I haven’t quantified Type I and II error rates so far, but my experience from working with several datasets and the feedback from colleagues suggest that errors are minimal. I’m also optimistic about the function’s ability to generalize across data from different search engines since the tested files represent data from commonly used sources.</p>
<p>Computational cost and execution speed were issues with my initial (simplistic) loop-based approach. I did some optimzation that included preprocessing titles to escape special characters, or the use of parallel processing. This reduced the execution time for a 4191-row test file significantly (down from 2856 s to about 952 s). It’s not lightning fast, but it’s acceptable for vanilla R code. I hope to port the code to C++ to speed up processing time for future projects. We’ll see …</p>
</details></section>
</details></section>
<section id="how-isotropic-scaling-in-gpa-works" class="level2">
<h2 class="anchored" data-anchor-id="how-isotropic-scaling-in-gpa-works">How Isotropic Scaling in GPA Works</h2>
<details>
<summary>
Click to expand
</summary>
<p>This entry is more of a mental note for my future self than anything else (which I guess most of this blog is tbh).</p>
<p>If you’ve ever worked with Generalized Procrustes Analysis (GPA) in statistical shape modeling, you’ve probably come across the <em>isotropic scaling</em> step. It sounds innocent enough — just scale all coordinates equally — but this step is both powerful and a little sneaky. Let’s unpack what’s really going on.</p>
<section id="where-it-fits-in-gpa" class="level3">
<h3 class="anchored" data-anchor-id="where-it-fits-in-gpa">Where it fits in GPA</h3>
<p>The core idea of GPA is to remove differences that are <em>not</em> actual shape variation — things like translation, rotation, and scale — so that PCA or other analyses reflect pure shape.</p>
<p>For each shape (X) compared to a reference (often the current mean shape), GPA does:</p>
<ol type="1">
<li><strong>Translation:</strong> Move the centroid to the origin.</li>
<li><strong>Isotropic scaling:</strong> Resize uniformly in all directions to match the reference size.</li>
<li><strong>Rotation:</strong> Rotate to minimize the distance to the reference.</li>
</ol>
<p>Then it updates the mean shape and repeats until everything stops changing much.</p>
</section>
<section id="what-isotropic-scaling-really-is" class="level3">
<h3 class="anchored" data-anchor-id="what-isotropic-scaling-really-is">What isotropic scaling really is</h3>
<p>Isotropic scaling means multiplying <strong>all</strong> coordinates by the same scalar (s).<br>
No stretching in one direction, no skewing — every axis gets scaled equally.</p>
<p>Mathematically, if (X ^{k m}) is a translated shape (with (k) points in (m) dimensions, usually (m=2) or (3)), the scaled shape is:</p>
<p><span class="math display">\[
X_{\text{scaled}} = s \, X
\]</span></p>
<p>The scalar (s &gt; 0) is chosen so that the scaled shape is as close as possible to the reference (Y).</p>
</section>
<section id="deriving-the-scaling-factor" class="level3">
<h3 class="anchored" data-anchor-id="deriving-the-scaling-factor">Deriving the scaling factor</h3>
<p>We want to minimize the squared Procrustes distance:</p>
<p><span class="math display">\[
D^2(s) = \|\, sX - Y \,\|_F^2
\]</span></p>
<p>where (||_F) is the Frobenius norm (sum of squared coordinates, square-rooted).</p>
<p>Expanding and differentiating with respect to (s):</p>
<p><span class="math display">\[
D^2(s) = s^2 \sum_{i,j} X_{ij}^2 - 2s \sum_{i,j} X_{ij} Y_{ij} + \sum_{i,j} Y_{ij}^2
\]</span></p>
<p>Set derivative to zero:</p>
<p><span class="math display">\[
2s \sum_{i,j} X_{ij}^2 - 2 \sum_{i,j} X_{ij} Y_{ij} = 0
\]</span></p>
<p>And solve:</p>
<p><span class="math display">\[
s = \frac{\sum_{i,j} X_{ij} Y_{ij}}{\sum_{i,j} X_{ij}^2}
\]</span></p>
<p>In matrix form:</p>
<p><span class="math display">\[
s = \frac{\mathrm{trace}(X^\mathsf{T} Y)}{\mathrm{trace}(X^\mathsf{T} X)}
\]</span></p>
</section>
<section id="the-centroid-size-connection" class="level3">
<h3 class="anchored" data-anchor-id="the-centroid-size-connection">The centroid size connection</h3>
<p>If no specific reference is chosen yet (e.g., the very first iteration), shapes are often scaled to <strong>unit centroid size</strong>:</p>
<p><span class="math display">\[
C = \sqrt{\sum_{i=1}^k \sum_{j=1}^m X_{ij}^2}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
s = \frac{1}{C}
\]</span></p>
<p>This prevents large shapes from dominating the mean early on.</p>
</section>
<section id="why-it-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-it-matters">Why it matters</h3>
<p>Without scaling, size differences will dominate PCA.<br>
With isotropic scaling, we remove those size differences, leaving only relative point configurations.<br>
That’s great for <em>pure shape</em> analysis — but it can be risky if size is biologically meaningful.</p>
<p>And here’s the catch: isotropic scaling ties <em>all</em> coordinate axes to a single size factor.<br>
If your sample varies in length or width, this scaling will also change <strong>vertical coordinates</strong>, even if they were identical before.<br>
That can create <em>artificial deformation</em> in anisotropic structures like weight-bearing feet — a subtle source of bias you might not expect.</p>
<hr>
<p>So, isotropic scaling: simple to describe, easy to code, but worth thinking about carefully.<br>
Because sometimes, what looks like a “neutral” preprocessing step can quietly rewrite your shape story.</p>
</section>
</details></section>
<section id="disco-diffusion-music-video" class="level2">
<h2 class="anchored" data-anchor-id="disco-diffusion-music-video">Disco Diffusion Music Video</h2>
<details>
<summary>
Click to expand
</summary>
<p>This post is about a (‘AI’-generated) music video that I created for my Band <a href="https://ictrl.bandcamp.com/track/dead-horse">ICTRL</a>. Before I go on with the nerdy details, you should check out the video first:</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
<iframe width="100%" height="100%" src="https://www.youtube.com/embed/l7dXeudFoDc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
</iframe>
</div>
<p>The video illustrates our song Dead Horse, which is the first of a bunch of singles we are going to drop this year. The idea to create a video like this was inspired by a <a href="https://www.reddit.com/r/KGATLW/comments/1bxew7e/is_the_iron_lung_music_video_really_ai/">Reddit post</a> about a recent video by one of my favorite bands: King Gizzard and the Lizzard Wizard (the song is called Iron Lung). The post provided some insights into how the video was created, e.g.&nbsp;this quote from user <em>No_Stay2400</em>:</p>
<p><em>“From Spod, the guy who made it (in a Reddit post back when it came out): Cheers, yeah it was 2 months of trial and error, and using a bunch of different techniques alongside the newest diffusion programs as they rolled out. It was all mapped out frame by frame to work with the music, trying see if I could illustrate the feeling of the music through the video. At times it feels like driving a bus from the backseat, but is amazing when it all comes together. The hardest thing is steering it away from the generic look that AI art can get. Anyway, thanks.”</em></p>
<!-- https://www.reddit.com/r/KGATLW/comments/xvdigb/music_video_iron_lung_ice_death_planets_lungs/ -->
<p>The main tool that caught my interest was Disco Diffusion, a neat open-source AI tool for generative art. Imagine typing in some text prompt and getting intricate pieces of visual art (for all “future” readers of the last sentence: Imagine a world where ‘AI’ was a new and exciting thing). Quickly, the idea was born to create a low-budget video where the prompts and thus the video sequences fit the lyrics of the song.</p>
<!-- Disco Diffusion uses some pretty advanced deep learning models to make it all happen -->
<p>Disco Diffusion was developed using Google Colab, which is a free, cloud-based Jupyter notebook environment provided by Google. If you are a data scientist or machine learning practitioner, you have probably heard of it. Being cloud-based, Colab requires no setup or installation. Users can start coding immediately in their web browser. Colab supports Python, so it was easy to read and understand the code. That bein said, there’s absolutely no need for any programming skills, since there are empty fields for all relevant parameters, prompts etc. in the notebook.</p>
<!-- Colab notebooks and all generated files can be stored directly on Google Drive, making it easy to manage and share files.  -->
<p>Colab also provides access to powerful computational resources, including different GPUs and TPUs, which are essential for training deep learning models. There is a certain amount of free resources (so called compute units) one can use to test the setup and get some early images. That, however, is rather slow and these provided credits will be exhausted soon. So it makes sense to switch to the Colab Pro, which cost me roughly 50 Euros or so for a month. I know there’s also a <a href="https://github.com/MohamadZeina/Disco_Diffusion_Local">local version of Disco Diffusion</a>, but I didn’t consider my computation ressources enough to make a video in reasonable time, so I abandoned that for the moment. This may be something to investigate more in the future, especially since I’m not particularly keen on throwing my money towards Google. Well.</p>
<p>The Colab notebook itself is pretty much self-explanatory. One has to run a bunch of cells to check GPU status, prepare folders and connect a (cloud) drive, import dependencies and set up runtime devices, define necessary functions and so on. The first interesting part are the diffusion and CLIP model settings. I watched a bunch of Youtube videos such as <a href="https://www.youtube.com/watch?v=gWxmtdZL8FE">this one</a> where they explained which settings worked for them. Copying mostly from that, I used a “512x512_diffusion_uncond_finetune_008100” diffusion model and checked the ‘use_secondary_model’ box.</p>
<p>The next big thing are the settings. Here I set the number of steps to 150. this values, I believe, is responsible for the amount of details in a single frame. I further set the picture dimension to [1280, 768]. For all the rest, I stuck with the default settings.</p>
<p>For the animation settings, I chose the 2D animation mode, checked the ‘key_frames’ box, and set ‘max_frames’ to 3500. I calculated the number of frames (3500) to make the length of the video match the length of the song at the chosen framerate of 12 fps. To create the movement you can see in the video, I changed the following parameters (leaving the rest at default):</p>
<blockquote class="blockquote">
<p>interp_spline = ‘Linear’<br>
angle = “0:(1.03)”<br>
zoom = “0:(1.03)”<br>
translation_x = “0:(0)”<br>
translation_y = “0:(0)”<br>
translation_z = “0:(10.0)”</p>
</blockquote>
<p>Initially, I changed the values for the 3D rotation as well, which caused some hard to pin down errors. Took me way too long to figure that out and caused some real frustrations along the way.</p>
<p>Next in line was the design of the prompts. First of all, I spent a LOT of time figuring out which style I would like to have. The YouTube video linked above, created by a guy called Doctor Diffusion, used pictures from the Polish artist Zdzisław Beksiński, famously know for his dystopian surrealism, and the American artist Lisa Frank, who is known for rainbow and neon colors and stylized depictions of animals, including dolphins, pandas, and unicorns. I threw in some Edvard Munch, who’s paintings I admire since being in the Munch museum in Oslo, and I really liked what I saw. Here are the exact prompts I used:</p>
<blockquote class="blockquote">
<p>text_prompts = {<br>
0: [“A single horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
216: [“A single ear by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
300: [“A single cloud by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
300: [“A burning cloud by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
384: [“A single horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
468: [“A single running woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
684: [“A single vomiting woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
720: [“A single beating heart by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
888: [“A single race horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1080: [“A single curtain by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1164: [“A single crow by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1212: [“A picture of a broken spine by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1320: [“A picture of a torch by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1380: [“A single running woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1560: [“A single vomiting woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1656: [“A single running horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1860: [“A single bass player by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
1980: [“A single running horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
2100: [“A single running woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
2280: [“A single vomiting woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
2340: [“A picture of a screaming woman in the background by Zdzisław Beksiński and Edvard Munch, Trending on artstation.”],<br>
2400: [“A picture of a thunderstorm with fire in the background by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
2460: [“A picture of a screaming woman in the background by Zdzisław Beksiński and Edvard Munch, Trending on artstation.”],<br>
2520: [“A single vomiting woman by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
2700: [“A picture of a horse running through a thunderstorm by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
2940: [“A picture of a dying horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
3060: [“A picture of a golden ship in the sea by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
3144: [“A picture of a dying horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
3204: [“A picture of a horse in hell by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
3276: [“A picture of a horse by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”],<br>
3372: [“A picture of a rainbow by Zdzisław Beksiński and Lisa Frank, Trending on artstation.”]<br>
}</p>
</blockquote>
<p>For the actual creation of the video, I set the ‘blend’ to 0.5 and always started at the ‘final_frame’ when I had to rerun the script. This happened quite a few times, for instance because of errors or when I ran out of computing units.</p>
<p>Finally, after the animation was, it required some minor editing to overlay the audio track onto the video. Et voilà, a new video was born.</p>
</details></section>
<section id="isolating-bass-tracks" class="level2">
<h2 class="anchored" data-anchor-id="isolating-bass-tracks">Isolating Bass Tracks</h2>
<details>
<summary>
Click to expand
</summary>
<p>I am a fan Rick Beato’s YouTube channel, especially the series ‘What Makes This Song Great?’. Also, I always wondered how he got those isolated instrument tracks, especially the bass tracks. One reason, I assume, is that he’s a well-copnnected producer with access to separated high-quality tracks directly from the artists or record labels for his deep dives.</p>
<p>As for my motivation, I thought it would be helpful to have isolated bass tracks for songs I would like to learn. The problem, though, is that I’m neither a producer nor well-connected. Also, for much of the music I like, YouTube - despite it’s sheer endless content on almost every niche topic - does not provide either isolated bass tracks or bass players covering these songs. So I did some searching online and found that there a several ways to isolate tracks for single instruments. These include EQ and filtering, layering and reconstruction, and several audio separation techniques such as spectral editing or phase cancellation.</p>
<p>The most convenient way, at least for my purposes, seems to be machine learning and AI-based tools since they require the least amount of audio engineering know-how. My current go-to LLM suggested four options (assuming I need a free option available under Linux):</p>
<ul>
<li>Spleeter (by Deezer)</li>
<li>Demucs (by Facebook AI Research)</li>
<li>Open-Unmix</li>
<li>VocalRemover.org (Command-Line Interface)</li>
</ul>
<p>I decided to give Open-Unmix a try, mainly because of the description: “Open-Unmix is an open-source tool for music source separation, developed by the Music Technology Group at the Technical University of Madrid. It focuses on separating vocals, bass, and drums from music tracks.”</p>
<p>Well, I like open-source solutions and I have an academic background, so that was enough to convince me. As for the cons, Open-Unmix may be less computationally efficient, but that wasn’t my main concern at this stage. I may do a comparison of different tools in a future post, though. Open-Unmix utilizes a bidirectional LSTM architecture for effective separation and requires FFmpeg for audio processing. Also, like basically all the other tools in the list, Open-Unmix is Python-based. Here are the bash commands I used to set up everything:</p>
<ol type="1">
<li>Install Python 3 and essential tools</li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install python3 python3-venv python3-pip ffmpeg</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>python3 is the Python 3 interpreter. python3-venv is the module to create virtual environments. python3-pip ist the Python package installer and ffmpeg is, well ffmpeg ;-)</p>
<ol start="2" type="1">
<li>Create and activate a virtual environment</li>
</ol>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> venv openunmix_env</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> openunmix_env/bin/activate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="3" type="1">
<li>Upgrade pip within the virtual environment</li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">--upgrade</span> pip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="4" type="1">
<li>Install Open-Unmix and verify the installation</li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install openunmix</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">umx</span> <span class="at">--help</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>By the way, ‘deactivate’ allows one to leave the virtual environment.</p>
<p>For a first test, I chose the song Exoplanet by Mother Engine. If converted this (YouTube video) [https://www.youtube.com/watch?v=MJu7bSh_03I] to an MP3 file and used this bash command:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">umx</span> <span class="at">--outdir</span> ~/music/isolated_tracks ~/music/isolated_tracks/Exoplanet.mp3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>from which I got this error:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">torch.OutOfMemoryError:</span> CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 518.62 MiB is free. Including non-PyTorch memory, this process has 1.44 GiB memory in use. Of the allocated memory 1.36 GiB is allocated by PyTorch, and 44.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  <span class="er">(</span><span class="ex">https://pytorch.org/docs/stable/notes/cuda.html#environment-variables</span><span class="kw">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This error message indicates that my GPU does not have sufficient memory to process the audio file using Open-Unmix. I therefore switched to CPU Processing (instead of GPU processing).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">umx</span> <span class="at">--no-cuda</span> <span class="at">--outdir</span> ~/music/isolated_tracks ~/music/isolated_tracks/Exoplanet.mp3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This did the track and created a folder named ‘Exoplanet’ including isolated (*.wav) tracks for bass, drums, vocals and others in the same directory as the original MP3 file.</p>
<p>Here’s the isolated bass track for “Exoplanet” by Mother Engine:</p>
<p><a href="assets/audio/bass.mp3" target="_blank">🎧 Listen to “Exoplanet” Isolated Bass Track</a></p>
<!-- <audio controls> -->
<!--   <source src="bass.mp3" type="audio/mpeg"> -->
<!--   Your browser does not support the audio element. -->
<!-- </audio> -->
<!-- How can I track the time needed to process this on my system (system specs)? -->
<p>There are some additional tricks that may help improve the performance for future tries. I could, for instance, …</p>
<ol type="1">
<li>Optimize CPU processing</li>
</ol>
<p>For instance,</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">umx</span> <span class="at">--no-cuda</span> <span class="at">--outdir</span> ~/music/isolated_tracks ~/music/isolated_tracks/Exoplanet.mp3 <span class="at">--start</span> 30 <span class="at">--duration</span> 60</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>should processes a 60-second segment starting at 30 seconds into the track. I could also limit the number of targets/tracks to specific instruments (e.g., bass):</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">umx</span> <span class="at">--no-cuda</span> <span class="at">--outdir</span> ~/music/isolated_tracks <span class="at">--targets</span> bass ~/music/isolated_tracks/Exoplanet.mp3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="2" type="1">
<li><p>Explore alternative, faster and less resource-intensive tools such as Spleeter or Demucs.</p></li>
<li><p>Or I could use higher-quality audio files such as WAV, or FLAC instead of compressed formats like MP3. These may yield better separation results and may also reduce processing time due to less decoding overhead.</p></li>
</ol>



</details></section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/koda86\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 Koda86</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>